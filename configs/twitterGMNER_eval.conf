dataset_path = data/datasets/twitterGMNER/test.txt
config = configs/twitterGMNER_eval.conf
# checkpoint_path = data/checkpoints/twitter10k/twitter10k_train/best_0806/best_model/best_model.pth
checkpoint_path = [Your checkpoint_path]
types_path = data/datasets/twitterGMNER/twitter10k_types.json
# annotation path
xml_path = data/datasets/images_annotation
#detection model path
detection_path = data/datasets/Vinvl_detection_path
# raw image path
image_path = data/datasets/raw_images
# textual model
model_path = bert-base-cased
tokenizer_path = bert-base-cased
# vision model
vit_name = openai/clip-vit-base-patch32
local_rank = -1
world_size = -1
lowercase = False
sampling_processes = 4
label = twitter10k_eval
log_path = data/checkpoints/twitterGMNER
debug = False
device_id = 2
model_type = MQSPN
cpu = False
eval_batch_size = 8
prop_drop = 0.5
freeze_transformer = False
no_overlapping = True
no_partial_overlapping = True
no_duplicate = True
cls_threshold = 0.0
boundary_threshold = 0.0
pos_size = 25
char_lstm_layers = 1
lstm_layers = 3
char_size = 50
char_lstm_drop = 0.2
use_glove = False
use_pos = False
use_char_lstm = False
use_lstm = False
pool_type = max
use_token_level_encoder = True
num_token_entity_encoderlayer = 5
entity_queries_num = 60
candidate_regions_num = 15
mask_ent2tok = True
mask_tok2ent = False
mask_ent2ent = True
mask_entself = True
word_mask_ent2tok = True
word_mask_tok2ent = False
word_mask_ent2ent = True
word_mask_entself = True
use_entity_pos = True
last_layer_for_loss = 3
seed = 47
